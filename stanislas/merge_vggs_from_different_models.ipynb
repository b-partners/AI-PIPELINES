{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "def clean_vgg_from_duplicates(vgg_polygons_path = \"/home/adelb/Downloads/test_color (6).json\", out_vgg_path = \"/home/adelb/Downloads/test_color_clean.json\"):\n",
    "\n",
    "    with open(vgg_polygons_path, \"r\") as f:\n",
    "        vgg_polygons = json.load(f)\n",
    "    # -------------------------\n",
    "    # HELPER: POLYGON IoU\n",
    "    # -------------------------\n",
    "    def poly_in_poly(poly1, poly2):\n",
    "        if not poly1.is_valid:\n",
    "            poly1 = poly1.buffer(0)\n",
    "        if not poly2.is_valid:\n",
    "            poly2 = poly2.buffer(0)\n",
    "\n",
    "        inter = poly1.intersection(poly2).area\n",
    "        p1a = poly1.area \n",
    "        p2a = poly2.area \n",
    "        \n",
    "        p1_in_p2 = inter/p1a if p1a > 0 else 0\n",
    "        p2_in_p1 = inter/p2a if p2a > 0 else 0\n",
    "        \n",
    "        \n",
    "        return max(p1_in_p2, p2_in_p1)\n",
    "        \n",
    "    pip_thresh = 0.6\n",
    "\n",
    "    def polygon_iou(poly1, poly2):\n",
    "        # fix invalids\n",
    "        if not poly1.is_valid:\n",
    "            poly1 = poly1.buffer(0)\n",
    "        if not poly2.is_valid:\n",
    "            poly2 = poly2.buffer(0)\n",
    "\n",
    "        inter = poly1.intersection(poly2).area\n",
    "        union = poly1.union(poly2).area\n",
    "        return inter / union if union > 0 else 0\n",
    "    iou_thresh = 0.6\n",
    "    # -------------------------\n",
    "    # STEP 1 — DEDUPLICATE POLYGONS\n",
    "    # -------------------------\n",
    "    for img_key, img_data in vgg_polygons.items():\n",
    "        regions = img_data.get(\"regions\", [])\n",
    "\n",
    "        polys = []\n",
    "        for idx, region in enumerate(regions.values()):\n",
    "            shape = region[\"shape_attributes\"]\n",
    "            if shape[\"name\"] != \"polygon\":\n",
    "                continue\n",
    "            xs = shape[\"all_points_x\"]\n",
    "            ys = shape[\"all_points_y\"]\n",
    "            \n",
    "            coords = list(zip(xs, ys))\n",
    "            if len(coords) >= 3:  # need at least 3 distinct points\n",
    "                poly = Polygon(coords)\n",
    "            else:\n",
    "                continue\n",
    "            conf = float(region[\"region_attributes\"].get(\"confidence\", 0))\n",
    "            label = region[\"region_attributes\"].get(\"label\", '')\n",
    "\n",
    "            # Store separate dict, no shapely object in final structure\n",
    "            polys.append({\"poly\": poly, \"conf\": conf, \"label\": label, \"region\": dict(region)})\n",
    "\n",
    "        keep = {}\n",
    "        used = set()\n",
    "        k = 0\n",
    "        for i in range(len(polys)):\n",
    "            if i in used:\n",
    "                continue\n",
    "            best = polys[i]\n",
    "            for j in range(i + 1, len(polys)):\n",
    "                if j in used:\n",
    "                    continue\n",
    "                iou = polygon_iou(polys[i][\"poly\"], polys[j][\"poly\"])\n",
    "                pip = poly_in_poly(polys[i][\"poly\"], polys[j][\"poly\"])\n",
    "                if iou > iou_thresh or pip > pip_thresh:\n",
    "                    if polys[j][\"conf\"] > best['conf']:\n",
    "                        best = polys[j]\n",
    "                    used.add(j)\n",
    "            used.add(i)\n",
    "            keep[k] = best['region']\n",
    "            k += 1\n",
    "\n",
    "        vgg_polygons[img_key][\"regions\"] = keep\n",
    "        \n",
    "        \n",
    "    with open(out_vgg_path, 'w') as f:\n",
    "        json.dump(vgg_polygons, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd6d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import json\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def clean_vgg_from_duplicates_stream(\n",
    "    vgg_polygons_path=\"/home/adelb/Downloads/test_color (6).json\", \n",
    "    out_vgg_path=\"/home/adelb/Downloads/test_color_clean.json\"\n",
    "):\n",
    "    # -------------------------\n",
    "    # HELPER: POLYGON IoU\n",
    "    # -------------------------\n",
    "    def poly_in_poly(poly1, poly2):\n",
    "        if not poly1.is_valid:\n",
    "            poly1 = poly1.buffer(0)\n",
    "        if not poly2.is_valid:\n",
    "            poly2 = poly2.buffer(0)\n",
    "\n",
    "        inter = poly1.intersection(poly2).area\n",
    "        p1a = poly1.area \n",
    "        p2a = poly2.area \n",
    "        \n",
    "        p1_in_p2 = inter / p1a if p1a > 0 else 0\n",
    "        p2_in_p1 = inter / p2a if p2a > 0 else 0\n",
    "        \n",
    "        return max(p1_in_p2, p2_in_p1)\n",
    "\n",
    "    pip_thresh = 0.6\n",
    "\n",
    "    def polygon_iou(poly1, poly2):\n",
    "        if not poly1.is_valid:\n",
    "            poly1 = poly1.buffer(0)\n",
    "        if not poly2.is_valid:\n",
    "            poly2 = poly2.buffer(0)\n",
    "\n",
    "        inter = poly1.intersection(poly2).area\n",
    "        union = poly1.union(poly2).area\n",
    "        return inter / union if union > 0 else 0\n",
    "\n",
    "    iou_thresh = 0.6\n",
    "\n",
    "    # -------------------------\n",
    "    # STREAM PARSE & PROCESS\n",
    "    # -------------------------\n",
    "    with open(vgg_polygons_path, \"rb\") as f_in, open(out_vgg_path, \"w\") as f_out:\n",
    "        f_out.write(\"{\")  # start JSON\n",
    "\n",
    "        parser = ijson.kvitems(f_in, \"\")  # stream top-level dict (img_key → img_data)\n",
    "        first = True\n",
    "        for img_key, img_data in parser:\n",
    "            regions = img_data.get(\"regions\", {})\n",
    "\n",
    "            polys = []\n",
    "            for idx, region in regions.items():\n",
    "                shape = region[\"shape_attributes\"]\n",
    "                if shape[\"name\"] != \"polygon\":\n",
    "                    continue\n",
    "                xs = shape[\"all_points_x\"]\n",
    "                ys = shape[\"all_points_y\"]\n",
    "                coords = list(zip(xs, ys))\n",
    "                if len(coords) >= 3:\n",
    "                    poly = Polygon(coords)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                conf = float(region[\"region_attributes\"].get(\"confidence\", 0))\n",
    "                label = region[\"region_attributes\"].get(\"label\", '')\n",
    "\n",
    "                polys.append({\n",
    "                    \"poly\": poly,\n",
    "                    \"conf\": conf,\n",
    "                    \"label\": label,\n",
    "                    \"region\": dict(region)\n",
    "                })\n",
    "\n",
    "            keep = {}\n",
    "            used = set()\n",
    "            k = 0\n",
    "            for i in range(len(polys)):\n",
    "                if i in used:\n",
    "                    continue\n",
    "                best = polys[i]\n",
    "                for j in range(i + 1, len(polys)):\n",
    "                    if j in used:\n",
    "                        continue\n",
    "                    iou = polygon_iou(polys[i][\"poly\"], polys[j][\"poly\"])\n",
    "                    pip = poly_in_poly(polys[i][\"poly\"], polys[j][\"poly\"])\n",
    "                    if iou > iou_thresh or pip > pip_thresh:\n",
    "                        if polys[j][\"conf\"] > best[\"conf\"]:\n",
    "                            best = polys[j]\n",
    "                        used.add(j)\n",
    "                used.add(i)\n",
    "                keep[k] = best[\"region\"]\n",
    "                k += 1\n",
    "\n",
    "            # overwrite with cleaned regions\n",
    "            img_data[\"regions\"] = keep\n",
    "\n",
    "            # stream write JSON (avoid full dict in memory)\n",
    "            if not first:\n",
    "                f_out.write(\",\")\n",
    "            first = False\n",
    "            json.dump(img_key, f_out)\n",
    "            f_out.write(\":\")\n",
    "            json.dump(img_data, f_out)\n",
    "\n",
    "        f_out.write(\"}\")  # close JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1aa1ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Input / output paths\n",
    "def poly_to_point(input_json , output_json):\n",
    "\n",
    "    # Load VGG JSON\n",
    "    with open(input_json, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Iterate through all images\n",
    "    for image_key, image_data in data.items():\n",
    "        if \"regions\" not in image_data:\n",
    "            continue\n",
    "        \n",
    "        new_regions = {}\n",
    "        for reg_id, region in image_data[\"regions\"].items():\n",
    "            shape = region[\"shape_attributes\"]\n",
    "            \n",
    "            # Only process polygons\n",
    "            if shape[\"name\"] == \"polygon\":\n",
    "                xs = shape[\"all_points_x\"]\n",
    "                ys = shape[\"all_points_y\"]\n",
    "                if len(xs) == 0:\n",
    "                    print(shape)\n",
    "                    continue\n",
    "                # Compute centroid\n",
    "                cx = int(sum(xs) / len(xs))\n",
    "                cy = int(sum(ys) / len(ys))\n",
    "                \n",
    "                # Replace polygon with a point\n",
    "                new_shape = {\n",
    "                    \"name\": \"point\",\n",
    "                    \"cx\": cx,\n",
    "                    \"cy\": cy\n",
    "                }\n",
    "                \n",
    "                # Preserve region attributes (labels)\n",
    "                new_regions[reg_id] = {\n",
    "                    \"shape_attributes\": new_shape,\n",
    "                    \"region_attributes\": region.get(\"region_attributes\", {})\n",
    "                }\n",
    "            else:\n",
    "                # Keep other shapes unchanged (optional)\n",
    "                new_regions[reg_id] = region\n",
    "        \n",
    "        # Update regions\n",
    "        data[image_key][\"regions\"] = new_regions\n",
    "\n",
    "    # Save updated JSON\n",
    "    with open(output_json, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "    print(f\"✅ Converted {input_json} → {output_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa6165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Input files\n",
    "def merge_polys_points_labels(vgg_polygons_path, vgg_points_2_path, vgg_points_3_path, output_path, order = 'CTS'):\n",
    "\n",
    "    # Load JSON files\n",
    "    with open(vgg_polygons_path, \"r\") as f:\n",
    "        vgg_polygons = json.load(f)\n",
    "\n",
    "    with open(vgg_points_2_path, \"r\") as f:\n",
    "        vgg_points_2 = json.load(f)\n",
    "\n",
    "    with open(vgg_points_3_path, \"r\") as f:\n",
    "        vgg_points_3 = json.load(f)\n",
    "\n",
    "    # Helper: extract points from VGG\n",
    "    def extract_points(vgg_data):\n",
    "        points = {}\n",
    "        for img_key, img_data in vgg_data.items():\n",
    "            pts = []\n",
    "            for region in img_data['regions'].values():\n",
    "                shape = region[\"shape_attributes\"]\n",
    "                if shape[\"name\"] == \"point\":\n",
    "                    cx, cy = shape[\"cx\"], shape[\"cy\"]\n",
    "                    label = region[\"region_attributes\"].get(\"label\", \"\")\n",
    "                    conf = float(region[\"region_attributes\"].get(\"confidence\", 1.0))\n",
    "                    pts.append({\"point\": Point(cx, cy), \"label\": label, \"conf\": conf})\n",
    "            points[img_key] = pts\n",
    "        return points\n",
    "\n",
    "    # Extract all points from files 2 and 3\n",
    "    points_2 = extract_points(vgg_points_2)\n",
    "    points_3 = extract_points(vgg_points_3)\n",
    "\n",
    "    # Process polygons and update labels\n",
    "    for img_key, img_data in vgg_polygons.items():\n",
    "        regions = img_data.get(\"regions\", [])\n",
    "        img_points_2 = points_2.get(img_key, [])\n",
    "        img_points_3 = points_3.get(img_key, [])\n",
    "\n",
    "        for region in regions.values():\n",
    "            shape = region[\"shape_attributes\"]\n",
    "            if shape[\"name\"] != \"polygon\":\n",
    "                continue\n",
    "\n",
    "            # Original label\n",
    "            label1 = region[\"region_attributes\"].get(\"label\", \"\")\n",
    "            xs = shape[\"all_points_x\"]\n",
    "            ys = shape[\"all_points_y\"]\n",
    "            polygon = Polygon(zip(xs, ys))\n",
    "\n",
    "            labels_to_concat = [label1]\n",
    "\n",
    "            # ---- VGG2 ----\n",
    "            pts_inside_2 = [p for p in img_points_2 if polygon.contains(p[\"point\"]) and p[\"label\"]]\n",
    "            if pts_inside_2:\n",
    "                best_pt_2 = max(pts_inside_2, key=lambda x: x[\"conf\"])\n",
    "                if order == \"SCT\" or order == \"TCS\":\n",
    "                    labels_to_concat.insert(0, best_pt_2[\"label\"])\n",
    "                elif order == 'CTS':\n",
    "                    labels_to_concat.append(best_pt_2[\"label\"])\n",
    "                    \n",
    "            # ---- VGG3 ----\n",
    "            pts_inside_3 = [p for p in img_points_3 if polygon.contains(p[\"point\"]) and p[\"label\"]]\n",
    "            if pts_inside_3:\n",
    "                best_pt_3 = max(pts_inside_3, key=lambda x: x[\"conf\"])\n",
    "                if order == 'CTS' or order == 'TCS':\n",
    "                    labels_to_concat.append(best_pt_3[\"label\"])\n",
    "                elif order == \"SCT\":\n",
    "                    labels_to_concat.insert(1, best_pt_3[\"label\"])\n",
    "\n",
    "            # Final label = unique + sorted\n",
    "            final_label = \"_\".join(labels_to_concat)\n",
    "            region[\"region_attributes\"][\"label\"] = final_label\n",
    "\n",
    "    # Save updated VGG JSON\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(vgg_polygons, f, indent=2)\n",
    "\n",
    "    print(f\"✅ Updated VGG JSON saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb60b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def add_polys_diff_label(cts_path, tcts_path, scts_path, out_path): \n",
    "    def get_labels(regions):\n",
    "        return set(reg['region_attributes']['label'] for reg in regions)\n",
    "\n",
    "    with open(tcts_path) as f:\n",
    "        TCTS = json.load(f)\n",
    "        \n",
    "    with open(cts_path) as f:\n",
    "        CTS = json.load(f)\n",
    "        \n",
    "    with open(scts_path) as f:\n",
    "        SCTS = json.load(f)\n",
    "\n",
    "    NCTS = deepcopy(CTS)\n",
    "    \n",
    "    for fn, data in NCTS.items():\n",
    "        labels = get_labels(data['regions'].values())\n",
    "        if fn in TCTS.keys():\n",
    "            lbls = set()\n",
    "            for reg in TCTS[fn]['regions'].values():\n",
    "                lbl = reg['region_attributes']['label']\n",
    "                if lbl not in labels:\n",
    "                    data['regions'][str(len(data['regions']))] = reg\n",
    "                    lbls.add(lbl)\n",
    "            labels.update(lbls)\n",
    "        if fn in SCTS.keys():\n",
    "            for reg in SCTS[fn]['regions'].values():\n",
    "                lbl = reg['region_attributes']['label']\n",
    "                if lbl not in labels:\n",
    "                    data['regions'][str(len(data['regions']))] = reg\n",
    "                    \n",
    "    with open(out_path, 'w') as f:\n",
    "        json.dump(NCTS, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_path = f'/home/adelb/Downloads/test_color (6).json'\n",
    "clean_path = f'/home/adelb/Downloads/test_color_clean.json'\n",
    "\n",
    "clean_vgg_from_duplicates(raw_path, clean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255061c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning typo: done\n",
      "cleaning state: done\n"
     ]
    }
   ],
   "source": [
    "exp = \"typo\"\n",
    "raw_path = f'big_VGGs/big_test_{exp}.json'\n",
    "clean_path = f'big_VGGs/big_test_{exp}_clean.json'\n",
    "\n",
    "clean_vgg_from_duplicates(raw_path, clean_path)\n",
    "\n",
    "print(f\"cleaning {exp}: done\")\n",
    "\n",
    "exp = \"state\"\n",
    "raw_path = f'big_VGGs/big_test_{exp}.json'\n",
    "clean_path = f'big_VGGs/big_test_{exp}_clean.json'\n",
    "\n",
    "clean_vgg_from_duplicates(raw_path, clean_path)\n",
    "\n",
    "print(f\"cleaning {exp}: done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c86df5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Converted /home/adelb/Downloads/test_sahi_color_clean.json → big_VGGs/big_test_color_point.json\n",
      "pointing color: done\n",
      "✅ Converted /home/adelb/Downloads/test_sahi_typo_clean.json → big_VGGs/big_test_typo_point.json\n",
      "pointing typo: done\n",
      "✅ Converted /home/adelb/Downloads/test_sahi_state_clean.json → big_VGGs/big_test_state_point.json\n",
      "pointing state: done\n"
     ]
    }
   ],
   "source": [
    "exp = \"color\"\n",
    "\n",
    "clean_path = f'/home/adelb/Downloads/test_sahi_{exp}_clean.json'\n",
    "point_path = f'big_VGGs/big_test_{exp}_point.json'\n",
    "\n",
    "poly_to_point(clean_path, point_path)\n",
    "\n",
    "print(f\"pointing {exp}: done\")\n",
    "\n",
    "exp = \"typo\"\n",
    "\n",
    "clean_path = f'/home/adelb/Downloads/test_sahi_{exp}_clean.json'\n",
    "point_path = f'big_VGGs/big_test_{exp}_point.json'\n",
    "\n",
    "poly_to_point(clean_path, point_path)\n",
    "\n",
    "print(f\"pointing {exp}: done\")\n",
    "\n",
    "exp = \"state\"\n",
    "\n",
    "clean_path = f'/home/adelb/Downloads/test_sahi_{exp}_clean.json'\n",
    "point_path = f'big_VGGs/big_test_{exp}_point.json'\n",
    "\n",
    "poly_to_point(clean_path, point_path)\n",
    "\n",
    "print(f\"pointing {exp}: done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf516c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated VGG JSON saved to: big_VGGs/big_test_CTS_full.json\n",
      "Merging CTS: Done\n",
      "✅ Updated VGG JSON saved to: big_VGGs/big_test_TCS_full.json\n",
      "Merging TCS: Done\n",
      "✅ Updated VGG JSON saved to: big_VGGs/big_test_SCT_full.json\n",
      "Merging SCT: Done\n"
     ]
    }
   ],
   "source": [
    "order = \"CTS\"\n",
    "\n",
    "poly_path = f'/home/adelb/Downloads/test_sahi_color_clean.json'\n",
    "points_path_1 = 'big_VGGs/big_test_typo_point.json'\n",
    "points_path_2 = 'big_VGGs/big_test_state_point.json'\n",
    "\n",
    "out_path = f'big_VGGs/big_test_{order}_full.json'\n",
    "\n",
    "merge_polys_points_labels(poly_path, points_path_1, points_path_2, out_path, order)\n",
    "\n",
    "print(f\"Merging {order}: Done\")\n",
    "\n",
    "order = \"TCS\"\n",
    "\n",
    "poly_path = '/home/adelb/Downloads/test_sahi_typo_clean.json'\n",
    "points_path_1 = 'big_VGGs/big_test_color_point.json'\n",
    "points_path_2 = 'big_VGGs/big_test_state_point.json'\n",
    "\n",
    "out_path = f'big_VGGs/big_test_{order}_full.json'\n",
    "\n",
    "merge_polys_points_labels(poly_path, points_path_1, points_path_2, out_path, order)\n",
    "\n",
    "print(f\"Merging {order}: Done\")\n",
    "\n",
    "order = \"SCT\"\n",
    "\n",
    "poly_path = '/home/adelb/Downloads/test_sahi_state_clean.json'\n",
    "points_path_1 = 'big_VGGs/big_test_color_point.json'\n",
    "points_path_2 = 'big_VGGs/big_test_typo_point.json'\n",
    "\n",
    "out_path = f'big_VGGs/big_test_{order}_full.json'\n",
    "\n",
    "merge_polys_points_labels(poly_path, points_path_1, points_path_2, out_path, order)\n",
    "\n",
    "print(f\"Merging {order}: Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9409cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cts_path = \"big_VGGs/big_test_CTS_full.json\"\n",
    "tcts_path = \"big_VGGs/big_test_TCS_full.json\"\n",
    "scts_path = \"big_VGGs/big_test_SCT_full.json\"\n",
    "ncts_path = \"big_VGGs/big_test_NCTS_full.json\"\n",
    "\n",
    "add_polys_diff_label(cts_path, tcts_path, scts_path, ncts_path)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a93016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ijson\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.strtree import STRtree\n",
    "\n",
    "def clean_vgg_from_duplicates_stream(\n",
    "    vgg_polygons_path=\"res_VGGs/TEST_New_CTS.json\",\n",
    "    out_vgg_path=\"res_VGGs/TEST_New_CTS_clean.json\",\n",
    "    iou_thresh=0.6,\n",
    "    pip_thresh=0.6,\n",
    "):\n",
    "    # -------------------------\n",
    "    # HELPERS\n",
    "    # -------------------------\n",
    "    def fix_poly(poly):\n",
    "        if not poly.is_valid:\n",
    "            poly = poly.buffer(0)\n",
    "        return poly\n",
    "\n",
    "    def polygon_iou(poly1, poly2):\n",
    "        poly1, poly2 = fix_poly(poly1), fix_poly(poly2)\n",
    "        inter = poly1.intersection(poly2).area\n",
    "        union = poly1.union(poly2).area\n",
    "        return inter / union if union > 0 else 0\n",
    "\n",
    "    def poly_in_poly(poly1, poly2):\n",
    "        poly1, poly2 = fix_poly(poly1), fix_poly(poly2)\n",
    "        inter = poly1.intersection(poly2).area\n",
    "        p1a, p2a = poly1.area, poly2.area\n",
    "        p1_in_p2 = inter / p1a if p1a > 0 else 0\n",
    "        p2_in_p1 = inter / p2a if p2a > 0 else 0\n",
    "        return max(p1_in_p2, p2_in_p1)\n",
    "\n",
    "    # -------------------------\n",
    "    # STREAM INPUT & WRITE OUTPUT\n",
    "    # -------------------------\n",
    "    with open(vgg_polygons_path, \"r\") as f_in, open(out_vgg_path, \"w\") as f_out:\n",
    "        f_out.write(\"{\\n\")\n",
    "        first = True\n",
    "\n",
    "        for img_key, img_data in ijson.kvitems(f_in, \"\", use_float=True):\n",
    "            regions = img_data.get(\"regions\", {})\n",
    "\n",
    "            polys = []\n",
    "            for region in regions.values():\n",
    "                shape = region[\"shape_attributes\"]\n",
    "                if shape[\"name\"] != \"polygon\":\n",
    "                    continue\n",
    "\n",
    "                xs, ys = shape[\"all_points_x\"], shape[\"all_points_y\"]\n",
    "                coords = list(zip(xs, ys))\n",
    "                if len(coords) < 3:\n",
    "                    continue\n",
    "\n",
    "                poly = Polygon(coords)\n",
    "                conf = float(region[\"region_attributes\"].get(\"confidence\", 0))\n",
    "                label = region[\"region_attributes\"].get(\"label\", \"\")\n",
    "                polys.append(\n",
    "                    {\"poly\": poly, \"conf\": conf, \"label\": label, \"region\": dict(region)}\n",
    "                )\n",
    "\n",
    "            # Deduplication using STRtree\n",
    "            keep = {}\n",
    "            if polys:\n",
    "                tree = STRtree([p[\"poly\"] for p in polys])\n",
    "                used = set()\n",
    "                k = 0\n",
    "\n",
    "                for i, p in enumerate(polys):\n",
    "                    if i in used:\n",
    "                        continue\n",
    "                    best = p\n",
    "                    # query candidates in same spatial vicinity\n",
    "                    candidates = tree.query(p[\"poly\"])\n",
    "                    for cand_poly in candidates:\n",
    "                        j = next(\n",
    "                            (idx for idx, pp in enumerate(polys) if pp[\"poly\"] == cand_poly),\n",
    "                            None,\n",
    "                        )\n",
    "                        if j is None or j == i or j in used:\n",
    "                            continue\n",
    "                        iou = polygon_iou(p[\"poly\"], polys[j][\"poly\"])\n",
    "                        pip = poly_in_poly(p[\"poly\"], polys[j][\"poly\"])\n",
    "                        if iou > iou_thresh or pip > pip_thresh:\n",
    "                            if polys[j][\"conf\"] > best[\"conf\"]:\n",
    "                                best = polys[j]\n",
    "                            used.add(j)\n",
    "                    used.add(i)\n",
    "                    keep[k] = best[\"region\"]\n",
    "                    k += 1\n",
    "\n",
    "            # Write cleaned image entry\n",
    "            cleaned_entry = {img_key: {\"regions\": keep}}\n",
    "            if not first:\n",
    "                f_out.write(\",\\n\")\n",
    "            else:\n",
    "                first = False\n",
    "            cleaned_entry_dumped = json.dumps(cleaned_entry)\n",
    "            f_out.write(cleaned_entry_dumped[1:-1])\n",
    "\n",
    "        f_out.write(\"\\n}\")\n",
    "    print(f\"✅ Cleaned VGG saved to {out_vgg_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc8adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned VGG saved to big_VGGs/big_test_NCTS_full_clean.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "raw_path = \"big_VGGs/big_test_NCTS_full.json\"\n",
    "clean_path = \"big_VGGs/big_test_NCTS_full_clean.json\"\n",
    "clean_vgg_from_duplicates_stream(raw_path, clean_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d3ff802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, ast\n",
    "\n",
    "cts_path = \"big_VGGs/big_test_CTS_full.json\"\n",
    "tcts_path = \"big_VGGs/big_test_TCS_full.json\"\n",
    "scts_path = \"big_VGGs/big_test_SCT_full.json\"\n",
    "nctsc_path = \"big_VGGs/big_test_NCTS_full_clean.json\"\n",
    "\n",
    "# with open(cts_path) as f:\n",
    "#     cts = json.load(f)\n",
    "    \n",
    "# with open(tcts_path) as f:\n",
    "#     tcts = json.load(f)\n",
    "    \n",
    "# with open(scts_path) as f:\n",
    "#     scts = json.load(f)\n",
    "    \n",
    "with open(nctsc_path) as f:\n",
    "    content = f.read().replace(\"'\", '\"')\n",
    "    nctsc = json.loads(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f225995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/adelb/Documents/Bpartners/Stanislas/big_VGGs/big_test_NCTS_full_clean.json'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.abspath('big_VGGs/big_test_NCTS_full_clean.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5710ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cts_labels = set(reg['region_attributes']['label'] for file in cts.values() for reg in file['regions'].values())\n",
    "# tcts_labels = set(reg['region_attributes']['label'] for file in tcts.values() for reg in file['regions'].values())\n",
    "# scts_labels = set(reg['region_attributes']['label'] for file in scts.values() for reg in file['regions'].values())\n",
    "ncts_labels = set(reg['region_attributes']['label'] for file in nctsc.values() for reg in file['regions'].values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d027c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'beige',\n",
       " 1: 'beige_boucharde',\n",
       " 2: 'beige_boucharde_degrade',\n",
       " 3: 'beige_boucharde_satisfaisant',\n",
       " 4: 'beige_degrade',\n",
       " 5: 'beige_flamme',\n",
       " 6: 'beige_flamme_degrade',\n",
       " 7: 'beige_flamme_satisfaisant',\n",
       " 8: 'beige_satisfaisant',\n",
       " 9: 'beige_spuntato',\n",
       " 10: 'beige_spuntato_degrade',\n",
       " 11: 'beige_spuntato_satisfaisant',\n",
       " 12: 'bleu',\n",
       " 13: 'bleu_boucharde',\n",
       " 14: 'bleu_boucharde_degrade',\n",
       " 15: 'bleu_boucharde_satisfaisant',\n",
       " 16: 'bleu_degrade',\n",
       " 17: 'bleu_flamme',\n",
       " 18: 'bleu_flamme_degrade',\n",
       " 19: 'bleu_flamme_satisfaisant',\n",
       " 20: 'bleu_satisfaisant',\n",
       " 21: 'bleu_spuntato',\n",
       " 22: 'bleu_spuntato_degrade',\n",
       " 23: 'bleu_spuntato_satisfaisant',\n",
       " 24: 'boucharde',\n",
       " 25: 'boucharde_degrade',\n",
       " 26: 'boucharde_satisfaisant',\n",
       " 27: 'degrade',\n",
       " 28: 'degrade_boucharde',\n",
       " 29: 'degrade_flamme',\n",
       " 30: 'degrade_spuntato',\n",
       " 31: 'flamme',\n",
       " 32: 'flamme_degrade',\n",
       " 33: 'flamme_satisfaisant',\n",
       " 34: 'satisfaisant',\n",
       " 35: 'satisfaisant_boucharde',\n",
       " 36: 'satisfaisant_flamme',\n",
       " 37: 'satisfaisant_spuntato',\n",
       " 38: 'spuntato',\n",
       " 39: 'spuntato_degrade',\n",
       " 40: 'spuntato_satisfaisant'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i: lbl for i, lbl in enumerate(sorted(ncts_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0e44082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38008"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nctsc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
