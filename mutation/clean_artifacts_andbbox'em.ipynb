{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d24514",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27437/3132260122.py:34: UserWarning: `keep_geom_type=True` in overlay resulted in 14 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  buf_demolitions = gpd.overlay(gdf_old_buf, gdf_new_buf, how=\"difference\")\n",
      "/tmp/ipykernel_27437/3132260122.py:35: UserWarning: `keep_geom_type=True` in overlay resulted in 25 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  buf_constructions = gpd.overlay(gdf_new_buf, gdf_old_buf, how=\"difference\")\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import CAP_STYLE, JOIN_STYLE\n",
    "\n",
    "# === USER PARAMETERS ===\n",
    "buffer_dist = 10  # Example: 5 meters\n",
    "frac_buf_dist = 0.05\n",
    "old_path = \"/home/adelb/Downloads/bati-2015.geojson\"\n",
    "new_path = \"/home/adelb/Downloads/bati-2022.geojson\"\n",
    "\n",
    "\n",
    "# === Load and clean GeoJSONs ===\n",
    "gdf_old = gpd.read_file(old_path).buffer(0)\n",
    "gdf_new = gpd.read_file(new_path).buffer(0)\n",
    "\n",
    "gdf_old = gpd.GeoDataFrame(geometry=gdf_old, crs=\"EPSG:3857\")\n",
    "gdf_new = gpd.GeoDataFrame(geometry=gdf_new, crs=\"EPSG:3857\")\n",
    "\n",
    "# === Apply positive buffer with FLAT ends and MITRE corners ===\n",
    "gdf_old_buf = gdf_old.geometry.apply(lambda geom: geom.buffer(\n",
    "    buffer_dist,\n",
    "    cap_style=CAP_STYLE.flat,\n",
    "    join_style=JOIN_STYLE.mitre\n",
    "))\n",
    "gdf_new_buf = gdf_new.geometry.apply(lambda geom: geom.buffer(\n",
    "    buffer_dist,\n",
    "    cap_style=CAP_STYLE.flat,\n",
    "    join_style=JOIN_STYLE.mitre\n",
    "))\n",
    "\n",
    "gdf_old_buf = gpd.GeoDataFrame(geometry=gdf_old_buf, crs=gdf_old.crs)\n",
    "gdf_new_buf = gpd.GeoDataFrame(geometry=gdf_new_buf, crs=gdf_new.crs)\n",
    "\n",
    "# === Compute buffered differences ===\n",
    "buf_demolitions = gpd.overlay(gdf_old_buf, gdf_new_buf, how=\"difference\")\n",
    "buf_constructions = gpd.overlay(gdf_new_buf, gdf_old_buf, how=\"difference\")\n",
    "\n",
    "# === Apply negative buffer to remove added margin ===\n",
    "neg_buf = -(1 + frac_buf_dist) * buffer_dist\n",
    "\n",
    "demolitions = buf_demolitions.geometry.apply(lambda geom: geom.buffer(\n",
    "    neg_buf,\n",
    "    cap_style=CAP_STYLE.flat,\n",
    "    join_style=JOIN_STYLE.mitre\n",
    "))\n",
    "constructions = buf_constructions.geometry.apply(lambda geom: geom.buffer(\n",
    "    neg_buf,\n",
    "    cap_style=CAP_STYLE.flat,\n",
    "    join_style=JOIN_STYLE.mitre\n",
    "))\n",
    "\n",
    "demolitions = gpd.GeoDataFrame(geometry=demolitions, crs=gdf_old.crs)\n",
    "constructions = gpd.GeoDataFrame(geometry=constructions, crs=gdf_old.crs)\n",
    "\n",
    "# === Optional: Save to files ===\n",
    "demolitions.to_file(\"noisy_demolitions.geojson\", driver=\"GeoJSON\")\n",
    "constructions.to_file(\"noisy_constructions.geojson\", driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import box, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def filter_comparison_by_intersection(reference_path, comparison_path, inter_frac=0.5):\n",
    "    # Read GeoJSON files\n",
    "    reference_gdf = gpd.read_file(reference_path)\n",
    "    comparison_gdf = gpd.read_file(comparison_path)\n",
    "\n",
    "    # Fix invalid geometries\n",
    "    reference_gdf['geometry'] = reference_gdf.geometry.buffer(0)\n",
    "    comparison_gdf['geometry'] = comparison_gdf.geometry.buffer(0)\n",
    "\n",
    "    # Ensure CRS match\n",
    "    if reference_gdf.crs != comparison_gdf.crs:\n",
    "        comparison_gdf = comparison_gdf.to_crs(reference_gdf.crs)\n",
    "\n",
    "    # Store geometries to keep\n",
    "    kept_geoms = []\n",
    "\n",
    "    for comp_geom in comparison_gdf.geometry:\n",
    "        intersected = reference_gdf[reference_gdf.intersects(comp_geom)]\n",
    "\n",
    "        keep = False\n",
    "        for ref_geom in intersected.geometry:\n",
    "            if ref_geom.area == 0:\n",
    "                continue  # Avoid division by zero\n",
    "            intersection_area = comp_geom.intersection(ref_geom).area\n",
    "            if (intersection_area / ref_geom.area) > inter_frac:\n",
    "                keep = True\n",
    "                break\n",
    "\n",
    "        if keep:\n",
    "            kept_geoms.append(comp_geom)\n",
    "\n",
    "    # Create new GeoDataFrame with kept geometries\n",
    "    kept_gdf = gpd.GeoDataFrame(geometry=kept_geoms, crs=comparison_gdf.crs)\n",
    "    return kept_gdf\n",
    "\n",
    "\n",
    "def cluster_and_bbox_flexible_merged(\n",
    "    geojson_path,\n",
    "    area_thresh=10.0,\n",
    "    max_distance=20.0,\n",
    "    num_bati=3,\n",
    "    minimal_bbox_area=100.0\n",
    "):\n",
    "    # Step 1: Read and fix invalid geometries\n",
    "    gdf = gpd.read_file(geojson_path)\n",
    "    gdf['geometry'] = gdf.geometry.buffer(0)\n",
    "\n",
    "    # Step 2: Filter small polygons\n",
    "    gdf = gdf[gdf.geometry.area >= area_thresh].reset_index(drop=True)\n",
    "    if gdf.empty:\n",
    "        return gpd.GeoDataFrame(columns=['geometry'], geometry='geometry', crs=gdf.crs)\n",
    "\n",
    "    gdf['cluster'] = -1\n",
    "    cluster_id = 0\n",
    "    remaining = gdf.copy()\n",
    "\n",
    "    # Step 3: Cluster with decreasing min_samples\n",
    "    for min_samples in range(num_bati, 0, -1):\n",
    "        if remaining.empty:\n",
    "            break\n",
    "\n",
    "        centroids = np.array([[geom.centroid.x, geom.centroid.y] for geom in remaining.geometry])\n",
    "        clustering = DBSCAN(eps=max_distance, min_samples=min_samples).fit(centroids)\n",
    "\n",
    "        labels = clustering.labels_\n",
    "        remaining['temp_cluster'] = labels\n",
    "\n",
    "        for label in set(labels):\n",
    "            if label == -1:\n",
    "                continue\n",
    "            mask = remaining['temp_cluster'] == label\n",
    "            if mask.sum() >= min_samples:\n",
    "                gdf.loc[remaining[mask].index, 'cluster'] = cluster_id\n",
    "                cluster_id += 1\n",
    "\n",
    "        remaining = remaining[remaining['temp_cluster'] == -1].drop(columns='temp_cluster')\n",
    "\n",
    "    # Step 4: Get bboxes for valid clusters\n",
    "    clustered = gdf[gdf['cluster'] != -1]\n",
    "    cluster_bboxes = [box(*unary_union(group.geometry).bounds) for _, group in clustered.groupby('cluster')]\n",
    "\n",
    "    # Step 5: Add bboxes for large unclustered geometries\n",
    "    unclustered = gdf[gdf['cluster'] == -1]\n",
    "    large_noise_bboxes = [\n",
    "        box(*geom.bounds)\n",
    "        for geom in unclustered.geometry\n",
    "        if geom.area >= 2 * area_thresh\n",
    "    ]\n",
    "\n",
    "    # Step 6: Merge overlapping bounding boxes\n",
    "    all_bboxes = cluster_bboxes + large_noise_bboxes\n",
    "    merged_union = unary_union(all_bboxes)\n",
    "\n",
    "    if isinstance(merged_union, Polygon):\n",
    "        merged_bboxes = [merged_union]\n",
    "    elif isinstance(merged_union, MultiPolygon):\n",
    "        merged_bboxes = list(merged_union.geoms)\n",
    "    else:\n",
    "        merged_bboxes = []\n",
    "\n",
    "    # Step 7: Filter out small bboxes\n",
    "    filtered_bboxes = [\n",
    "        poly for poly in merged_bboxes if poly.area >= minimal_bbox_area\n",
    "    ]\n",
    "\n",
    "    # Step 8: Return as GeoDataFrame\n",
    "    bbox_gdf = gpd.GeoDataFrame(geometry=filtered_bboxes, crs=gdf.crs)\n",
    "    return bbox_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917e69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_gdf = filter_comparison_by_intersection(new_path, 'noisy_constructions.geojson', inter_frac=0.4)\n",
    "filtered_gdf.to_file('cleaned_constructions.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555411cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_gdf = cluster_and_bbox_flexible_merged(\n",
    "    \"cleaned_constructions.geojson\",\n",
    "    area_thresh=60,\n",
    "    max_distance=100.0,\n",
    "    num_bati=7,\n",
    "    minimal_bbox_area= 300,\n",
    ")\n",
    "bbox_gdf.to_file(\"bbox_constructions_flexible_merged.geojson\", driver=\"GeoJSON\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
